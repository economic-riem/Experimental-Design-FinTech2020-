{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#安放路径\n",
    "import os\n",
    "\n",
    "# BASE_PATH = '../data'\n",
    "BASE_PATH = r'C:\\Users\\ljs11\\Desktop\\实验设计作业\\Final_code\\data'\n",
    "# BASE_PATH = '/Users/lijiale/Desktop/FinTech2020-master(爸爸方案)2/Final_code/data'\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(BASE_PATH, 'RawData')\n",
    "TEMP_DATA_PATH = os.path.join(BASE_PATH, \"TempData\")\n",
    "ETL_DATA_PATH = os.path.join(BASE_PATH, 'EtlData')\n",
    "RESULT_PATH = os.path.join(BASE_PATH, \"Result\")\n",
    "\n",
    "SUBMISSION = os.path.join(RESULT_PATH, 'submission.txt')\n",
    "########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取总数据表\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "real_data=pd.read_csv(r'C:\\Users\\ljs11\\Desktop\\实验设计作业\\Final_code\\data\\real_data.csv')\n",
    "########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31938, 92) (7985, 92)\n",
      "model: xgb. fold:  0 training...\n",
      "[0]\tvalidation_0-auc:0.745686\tvalidation_1-auc:0.702273\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[50]\tvalidation_0-auc:0.895629\tvalidation_1-auc:0.759876\n",
      "[100]\tvalidation_0-auc:0.929171\tvalidation_1-auc:0.753338\n",
      "Stopping. Best iteration:\n",
      "[48]\tvalidation_0-auc:0.89349\tvalidation_1-auc:0.760277\n",
      "\n",
      "model: xgb. fold:  1 training...\n",
      "[0]\tvalidation_0-auc:0.755129\tvalidation_1-auc:0.695086\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[50]\tvalidation_0-auc:0.898918\tvalidation_1-auc:0.743755\n",
      "[100]\tvalidation_0-auc:0.932226\tvalidation_1-auc:0.744593\n",
      "[150]\tvalidation_0-auc:0.951938\tvalidation_1-auc:0.744018\n",
      "[200]\tvalidation_0-auc:0.964479\tvalidation_1-auc:0.741274\n",
      "Stopping. Best iteration:\n",
      "[116]\tvalidation_0-auc:0.93932\tvalidation_1-auc:0.745354\n",
      "\n",
      "model: xgb. fold:  2 training...\n",
      "[0]\tvalidation_0-auc:0.750617\tvalidation_1-auc:0.718589\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[50]\tvalidation_0-auc:0.893045\tvalidation_1-auc:0.7619\n",
      "[100]\tvalidation_0-auc:0.929228\tvalidation_1-auc:0.759906\n",
      "Stopping. Best iteration:\n",
      "[44]\tvalidation_0-auc:0.883819\tvalidation_1-auc:0.763104\n",
      "\n",
      "model: xgb. fold:  3 training...\n",
      "[0]\tvalidation_0-auc:0.75033\tvalidation_1-auc:0.70436\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[50]\tvalidation_0-auc:0.897561\tvalidation_1-auc:0.762876\n",
      "[100]\tvalidation_0-auc:0.929861\tvalidation_1-auc:0.762829\n",
      "[150]\tvalidation_0-auc:0.94991\tvalidation_1-auc:0.762477\n",
      "Stopping. Best iteration:\n",
      "[86]\tvalidation_0-auc:0.92136\tvalidation_1-auc:0.764192\n",
      "\n",
      "model: xgb. fold:  4 training...\n",
      "[0]\tvalidation_0-auc:0.747447\tvalidation_1-auc:0.696343\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[50]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.74718\n",
      "[100]\tvalidation_0-auc:0.927269\tvalidation_1-auc:0.744766\n",
      "Stopping. Best iteration:\n",
      "[41]\tvalidation_0-auc:0.886733\tvalidation_1-auc:0.749415\n",
      "\n",
      "xgb cv score for valid is:  0.7564683999999999\n",
      "(31938, 92) (7985, 92)\n",
      "saving result...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#XGB模型\n",
    "import pandas as pd\n",
    "from parameter import *\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "train = real_data[real_data['TrainOrTest'] == 1]\n",
    "test = real_data[real_data['TrainOrTest'] == 0]\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "\n",
    "params_xgb = {\n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': 1000,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'gamma': 0.1,\n",
    "        'max_depth': 8,\n",
    "        'alpha': 0.3,\n",
    "        'lambda': 0.5,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'min_child_weight': 3,\n",
    "        'silent': 1,\n",
    "        'eta': 0.1,\n",
    "        'nthread': -1,\n",
    "        'seed': 2019,\n",
    "    }\n",
    "\n",
    "drop_fea = ['id', 'flag', 'isTest','TrainOrTest']\n",
    "    # features = [col for col in test.columns if col not in drop_fea]\n",
    "    # TOP100\n",
    "features = ['cur_credit_min_opn_dt_cnt', 'l1y_crd_card_csm_amt_dlm_cd', 'Dat_Flg1_Cd_per_count_amt_1',\n",
    "                'perm_crd_lmt_cd',\n",
    "                'Trx_Cod2_Cd54_recent_trd',\n",
    "                # 'cny_trx_amt_sum_6',\n",
    "                'Dat_Flg3_Cd1_recent_trd', 'acdm_deg_cd',\n",
    "                'cur_debit_min_opn_dt_cnt', 'Dat_Flg3_Cd_per_count_amt_1', 'Trx_Cod1_Cd_amt_2',\n",
    "                'Dat_Flg1_Cd_per_count_amt_0',\n",
    "                'Trx_Cod1_Cd_per_count_amt_2', 'Trx_Cod1_Cd_per_day_times_2', 'Trx_Cod1_Cd_amt_0', 'gdr_cd',\n",
    "                'Trx_Cod2_Cd_per_count_amt_36', 'pot_ast_lvl_cd', 'job_year',\n",
    "                # 'cny_trx_amt_sum_5',\n",
    "                'hld_crd_card_grd_cd',\n",
    "                'Trx_Cod1_Cd_per_count_amt_0', 'fr_or_sh_ind', 'age', '6_Dat_Flg3_Cd_times_1',\n",
    "                'Dat_Flg1_Cd_per_day_times_1',\n",
    "                'Trx_Cod1_Cd1_recent_trd', 'Trx_Cod2_Cd_per_day_times_2', 'Trx_Cod2_Cd_amt_36',\n",
    "                'Dat_Flg1_Cd5_per_day_times_0',\n",
    "                'per_day_trd_amt', 'Trx_Cod2_Cd53_recent_trd', 'Trx_Cod2_Cd5_per_day_times_26', 'his_lng_ovd_day',\n",
    "                'hav_car_grp_ind', 'Dat_Flg1_Cd5_per_day_times_1',\n",
    "                # 'Trx_Cod2_Cd1_recent_trd',\n",
    "                'Dat_Flg3_Cd_per_count_amt_0',\n",
    "                # 'trd_amt',\n",
    "                'dnl_bind_cmb_lif_ind', 'Trx_Cod2_Cd6_per_day_times_32', 'Trx_Cod2_Cd6_per_day_times_54',\n",
    "                'Trx_Cod2_Cd_amt_54', 'Dat_Flg1_Cd6_per_day_times_1', 'Trx_Cod2_Cd_per_count_amt_30',\n",
    "                'Trx_Cod2_Cd6_per_day_times_2', 'Dat_Flg3_Cd_amt_1', 'per_count_trd_amt',\n",
    "                'Trx_Cod2_Cd_per_day_times_46',\n",
    "                'Dat_Flg3_Cd6_per_day_times_1',\n",
    "                # 'Trx_Cod1_Cd2_recent_trd',\n",
    "                'frs_agn_dt_cnt', 'edu_deg_cd',\n",
    "                'Trx_Cod2_Cd_per_day_times_15', 'dnl_mbl_bnk_ind', 'Trx_Cod2_Cd29_recent_trd', 'Dat_Flg1_Cd_amt_1',\n",
    "                'Trx_Cod2_Cd_amt_32', 'Trx_Cod2_Cd_per_count_amt_55', 'crd_card_act_ind',\n",
    "                'Trx_Cod2_Cd_per_count_amt_32',\n",
    "                'Dat_Flg3_Cd_per_day_times_1', 'Trx_Cod2_Cd_amt_53', 'Trx_Cod2_Cd32_recent_trd', 'Dat_Flg1_Cd_amt_0',\n",
    "                'Trx_Cod2_Cd5_per_day_times_32', 'per_day_trd_times', 'Trx_Cod2_Cd_amt_55', 'Trx_Cod2_Cd_amt_30',\n",
    "                'Trx_Cod2_Cd_amt_52', '5_Trx_Cod2_Cd_times_54', 'Trx_Cod2_Cd_per_day_times_40',\n",
    "                'Trx_Cod2_Cd_per_count_amt_54',\n",
    "                'Trx_Cod2_Cd_per_day_times_3', 'Trx_Cod1_Cd5_per_day_times_2', 'Dat_Flg3_Cd_times_1',\n",
    "                'Trx_Cod2_Cd_per_day_times_54', 'Dat_Flg3_Cd5_per_day_times_1', '6_Trx_Cod2_Cd_times_10',\n",
    "                'Trx_Cod2_Cd6_per_day_times_1', 'Trx_Cod2_Cd5_per_day_times_30', 'Trx_Cod2_Cd_per_count_amt_11',\n",
    "                'Trx_Cod2_Cd_amt_24', 'Dat_Flg3_Cd_amt_0', 'Trx_Cod1_Cd6_per_day_times_2',\n",
    "                # 'Trx_Cod2_Cd30_recent_trd',\n",
    "                'Trx_Cod2_Cd_per_day_times_16', '6_Trx_Cod2_Cd_times_54', 'Trx_Cod2_Cd6_per_day_times_55',\n",
    "                'Trx_Cod2_Cd_per_day_times_32',\n",
    "                # 'Trx_Cod1_Cd0_recent_trd',\n",
    "                'Trx_Cod2_Cd_per_day_times_0',\n",
    "                'Trx_Cod1_Cd_per_day_times_1', 'Trx_Cod1_Cd_per_count_amt_1', 'Trx_Cod2_Cd_per_count_amt_21',\n",
    "                'Trx_Cod2_Cd_times_54', 'Dat_Flg1_Cd_per_day_times_0', 'Trx_Cod2_Cd5_per_day_times_54',\n",
    "                # 'Trx_Cod2_Cd16_recent_trd',\n",
    "                'Dat_Flg1_Cd0_recent_trd']\n",
    "\n",
    "\n",
    "train_X = train[features]\n",
    "train_y = train['flag']\n",
    "\n",
    "print(train_X.shape, test[features].shape)\n",
    "\n",
    "def xgb_model(train_X, label, test, params_xgb):\n",
    "    fea_dict = {v: k for k, v in enumerate(train_X.columns)}\n",
    "    train_X.columns = [fea_dict[v] for v in train_X.columns]\n",
    "    test.columns = train_X.columns\n",
    "\n",
    "    fea_dict = {v: k for k, v in fea_dict.items()}\n",
    "    # lgb 模型\n",
    "    cv_pred = np.zeros(test.shape[0])\n",
    "    cv_best_auc_all = 0\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)#5折交叉验证\n",
    "    # SKF = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)#10折交叉验证\n",
    "    # SKF = StratifiedKFold(n_splits=20, shuffle=True, random_state=2019)#20折交叉验证\n",
    "    # SKF = StratifiedKFold(n_splits=30, shuffle=True, random_state=2019)#30折交叉验证\n",
    "\n",
    "    skf = SKF.split(train_X, label)\n",
    "\n",
    "    fea_importances = pd.DataFrame({'column': train_X.columns})\n",
    "\n",
    "    stack_train = np.zeros((train.shape[0], 2))\n",
    "    stack_test = np.zeros((test.shape[0], 2))\n",
    "\n",
    "    for i, (train_fold, validate) in enumerate(skf):\n",
    "        print(\"model: xgb. fold: \", i, \"training...\")\n",
    "        X_train, label_train = train_X.iloc[train_fold], label.iloc[train_fold]\n",
    "        X_validate, label_validate = train_X.iloc[validate], label.iloc[validate]\n",
    "\n",
    "        model = xgb.XGBClassifier(**params_xgb)\n",
    "\n",
    "        model.fit(X_train, label_train,\n",
    "                  eval_set=[(X_train, label_train), (X_validate, label_validate)],\n",
    "                  early_stopping_rounds=100, verbose=50)\n",
    "\n",
    "        best_iteration = model.get_booster().best_iteration\n",
    "\n",
    "        cv_pred += model.predict_proba(test, ntree_limit=best_iteration)[:, 1]\n",
    "        cv_best_auc_all += model.best_score\n",
    "\n",
    "        score_va = model.predict_proba(train_X.iloc[validate], ntree_limit=best_iteration)\n",
    "        score_te = model.predict_proba(test, ntree_limit=best_iteration)\n",
    "        stack_train[validate] += score_va\n",
    "        stack_test += score_te\n",
    "\n",
    "    cv_pred /= 5\n",
    "    cv_best_auc_all /= 5\n",
    "    # valid_best_auc_all /= 5\n",
    "    print(\"xgb cv score for valid is: \", cv_best_auc_all)\n",
    "\n",
    "    stack_test /= 5\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "    df_stack = pd.DataFrame()\n",
    "\n",
    "    df_stack['xgb_prob'] = np.around(stack[:, 1], 6)\n",
    "    return cv_pred, fea_importances, df_stack\n",
    "\n",
    "result, feature_importance, df_stack = xgb_model(train_X, train_y, test[features], params_xgb)\n",
    "\n",
    "print(train_X.shape, test[features].shape)\n",
    "\n",
    "# print('\\n features(importance=0): ')\n",
    "# print(list(feature_importance[feature_importance['importance'] == 0]['column']))\n",
    "\n",
    "# saving result\n",
    "print('saving result...')\n",
    "submission['pred'] = result\n",
    "# submission.to_csv(SUBMISSION, index=False, header=0, encoding='utf-8', sep='\\t')\n",
    "submission.to_csv(r'C:\\Users\\ljs11\\Desktop\\实验设计作业\\Final_code\\data\\Result\\XGB改进_结果.csv', index=False, header=0, encoding='utf-8')\n",
    "print('done')\n",
    "\n",
    "\n",
    "##################################################################################################################\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}